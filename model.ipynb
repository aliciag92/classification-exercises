{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "from env import host, user, password \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using titanic data, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab acquired dataset\n",
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass  sibsp  parch     fare  alone  sex_male  \\\n",
       "0             0         0       3      1      0   7.2500      0         1   \n",
       "1             1         1       1      1      0  71.2833      0         0   \n",
       "2             2         1       3      0      0   7.9250      1         0   \n",
       "3             3         1       1      1      0  53.1000      0         0   \n",
       "4             4         0       3      0      0   8.0500      1         1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  \n",
       "3                       0                        1  \n",
       "4                       0                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab cleaned df\n",
    "df = prepare.clean_titanic(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (498, 10)\n",
      "validate -> (214, 10)\n",
      "test -> (179, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass  sibsp  parch      fare  alone  sex_male  \\\n",
       "583           583         0       1      0      0   40.1250      1         1   \n",
       "165           165         1       3      0      2   20.5250      0         1   \n",
       "50             50         0       3      4      1   39.6875      0         1   \n",
       "259           259         1       2      0      1   26.0000      0         0   \n",
       "306           306         1       1      0      0  110.8833      1         0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "583                       0                        0  \n",
       "165                       0                        1  \n",
       "50                        0                        1  \n",
       "259                       0                        1  \n",
       "306                       0                        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'train -> {train.shape}')\n",
    "print(f'validate -> {validate.shape}')\n",
    "print(f'test -> {test.shape}')\n",
    "\n",
    "#work w/ training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X inputs and y target variable for each split\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? *remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline prediction:\n",
    "#predicting the most prevalant class in training dataset(the mode)\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass  sibsp  parch      fare  alone  sex_male  \\\n",
       "583           583         0       1      0      0   40.1250      1         1   \n",
       "165           165         1       3      0      2   20.5250      0         1   \n",
       "50             50         0       3      4      1   39.6875      0         1   \n",
       "259           259         1       2      0      1   26.0000      0         0   \n",
       "306           306         1       1      0      0  110.8833      1         0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  baseline_prediction  \n",
       "583                       0                        0                    0  \n",
       "165                       0                        1                    0  \n",
       "50                        0                        1                    0  \n",
       "259                       0                        1                    0  \n",
       "306                       0                        0                    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline model would be to predict 0 since it is most prevalant\n",
    "train[\"baseline_prediction\"] = train.survived.value_counts().idxmax()\n",
    "train.head()\n",
    "\n",
    "#or train['baseline_prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n"
     ]
    }
   ],
   "source": [
    "#baseline accuracy:\n",
    "#when making baseline predictions, what is the accuracy?\n",
    "baseline_accuracy = (train.survived == train.baseline_prediction).mean()\n",
    "\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create/generate a blank, new Decision Tree model/object **with max_depth argument**\n",
    "clf1 = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit/train the model(decision tree classifier) to training data/sample\n",
    "# format: model.fit(X, y)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize\n",
    "dot_data = export_graphviz(clf1, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=['Did not survive', 'Survived'])\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform/make predictions using trained model (the training sample)\n",
    "y_pred = clf1.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62222222, 0.37777778],\n",
       "       [0.62222222, 0.37777778],\n",
       "       [0.89285714, 0.10714286],\n",
       "       [0.14814815, 0.85185185],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the probabilities for each class\n",
    "# aka get prediction probabilites for each class for each observation in train\n",
    "y_pred_proba = clf1.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set with max depth of 3: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the model\n",
    "print('Accuracy of Decision Tree classifier on training set with max depth of 3: {:.2f}'\n",
    "      .format(clf1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[274,  33],\n",
       "       [ 56, 135]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  274   33\n",
       "1   56  135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>274</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>56</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict_death  predict_survive\n",
       "actual_death              274               33\n",
       "actual_survive             56              135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn confusion matrix into a dataframe for human legibility\n",
    "conf_df = pd.DataFrame(conf, \n",
    "                       columns=['predict_death', 'predict_survive'], \n",
    "                       index=['actual_death', 'actual_survive'])\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], \n",
    "                         columns=['predict_death', 'predict_survive'], \n",
    "                         index=['actual_death', 'actual_survive'])\n",
    "rubric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       307\n",
      "           1       0.80      0.71      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.706806</td>\n",
       "      <td>0.752089</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.816937</td>\n",
       "      <td>0.799657</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820051</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.818787</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.830303  0.892508  0.860283  307.000000\n",
       "1              0.803571  0.706806  0.752089  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.816937  0.799657  0.806186  498.000000\n",
       "weighted avg   0.820051  0.821285  0.818787  498.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaner way to read classification report\n",
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "pd.DataFrame(class_report).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.706806</td>\n",
       "      <td>0.752089</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.816937</td>\n",
       "      <td>0.799657</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820051</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.818787</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.830303  0.892508  0.860283  307.000000\n",
       "survived       0.803571  0.706806  0.752089  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.816937  0.799657  0.806186  498.000000\n",
       "weighted avg   0.820051  0.821285  0.818787  498.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename classes\n",
    "pd.DataFrame(class_report).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821285140562249"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy (tp+tn/tp+tn+fp+fn)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068062827225131"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true positive rate (sensitivity aka recall) (tp/tp+fn)\n",
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10749185667752444"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false positive rate (fp/fp+tn)\n",
    "fp / (fp + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true negative rate (specificity) (tn/tn+fp)\n",
    "tn / tn + fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1696969696969697"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false negative rate (miss rate)(fn/fn+tp)\n",
    "fn / (fn + tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035714285714286"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision (positive predictive value) (tp/tp+fp)\n",
    "precision_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068062827225131"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall (aka sensitivity) (tp/tp+fn)\n",
    "recall_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520891364902508"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1-score (2*precision*recall / precision + recall)\n",
    "f1_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([307, 191])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#support (number of occurrences of each class in y_true)\n",
    "precision_recall_fscore_support(y_train, y_pred)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can create function to calculate these metrics\n",
    "def get_metrics_binary(clf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    accuracy = clf.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = conf[1][1] / conf[1].sum()\n",
    "    fpr = conf[0][1] / conf[0].sum()\n",
    "    tnr = conf[0][0] / conf[0].sum()\n",
    "    fnr = conf[1][0] / conf[1].sum()\n",
    "    print(f'''\n",
    "    The accuracy for our model is {accuracy:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.8213\n",
      "    The True Positive Rate is 0.707, The False Positive Rate is 0.107,\n",
      "    The True Negative Rate is 0.893, and the False Negative Rate is 0.293\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.892508</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.706806</td>\n",
       "      <td>0.752089</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.816937</td>\n",
       "      <td>0.799657</td>\n",
       "      <td>0.806186</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820051</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.818787</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.830303  0.892508  0.860283  307.000000\n",
       "1              0.803571  0.706806  0.752089  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.816937  0.799657  0.806186  498.000000\n",
       "weighted avg   0.820051  0.821285  0.818787  498.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "report_df = get_metrics_binary(clf1)\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different `max_depth` value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new blank decision tree w/ new max_depth value\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit/train the model(decision tree classifier) to training data/sample\n",
    "# format: model.fit(X, y)\n",
    "\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "clf2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize\n",
    "dot_data = export_graphviz(clf2, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=['Did not survive', 'Survived'])\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True, format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform/make predictions using trained model (the training sample)\n",
    "y_pred = clf2.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63636364, 0.36363636],\n",
       "       [0.63636364, 0.36363636],\n",
       "       [1.        , 0.        ],\n",
       "       [0.11538462, 0.88461538],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the probabilities for each class\n",
    "# aka get prediction probabilites for each class for each observation in train\n",
    "y_pred_proba = clf2.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set with max depth of 4: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the model\n",
    "print('Accuracy of Decision Tree classifier on training set with max depth of 4: {:.2f}'\n",
    "      .format(clf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[292,  15],\n",
       "       [ 66, 125]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8373493975903614\n",
      "true positive rate: 0.6544502617801047\n",
      "false positive rate: 0.048859934853420196\n",
      "true negative rate: 16.0\n",
      "false negative rate:0.18435754189944134\n",
      "precision: 0.8928571428571429\n",
      "recall: 0.6544502617801047\n",
      "f1-score: 0.7552870090634441\n",
      "support: [307 191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "#accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "#true positive rate\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "#false positive rate \n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "#true negative rate (specificity)\n",
    "tnr = tn / tn + fp\n",
    "\n",
    "#false negative rate (miss rate)\n",
    "fnr = fn / (fn + tn)\n",
    "\n",
    "#precision (positive predictive value)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "\n",
    "#recall (sensitivity)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "\n",
    "#f1-score\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "\n",
    "#support (number of occurrences of each class in y_true)\n",
    "support = precision_recall_fscore_support(y_train, y_pred)[-1]\n",
    "\n",
    "\n",
    "print(f'''\n",
    "Accuracy: {accuracy}\n",
    "true positive rate: {tpr}\n",
    "false positive rate: {fpr}\n",
    "true negative rate: {tnr}\n",
    "false negative rate:{fnr}\n",
    "precision: {precision}\n",
    "recall: {recall}\n",
    "f1-score: {f1}\n",
    "support: {support}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n",
    "\n",
    "- model 2 is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n",
      "clf1 accuracy: 82.13%\n",
      "clf2 accuracy: 83.73%\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "print('clf1 accuracy: 82.13%')\n",
    "print('clf2 accuracy: 83.73%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the `validate` set?\n",
    "\n",
    "- model 1 performed better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n",
      "Accuracy of Decision Tree classifier on validate set model 1: 0.78\n",
      "Accuracy of Decision Tree classifier on validate set model 2: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "print('Accuracy of Decision Tree classifier on validate set model 1: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))\n",
    "print('Accuracy of Decision Tree classifier on validate set model 2: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate model 1 on out-of-sample data\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the classification model trained on train data to make predictions on validate data\n",
    "y_pred = clf1.predict(X_validate)\n",
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    0\n",
       "424    0\n",
       "568    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.83       132\n",
      "           1       0.74      0.63      0.68        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare actual y values from validate to predictions based on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate model 2 on out-of-sample data\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the classification model trained on train data to make predictions on validate data\n",
    "y_pred = clf2.predict(X_validate)\n",
    "y_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610    0\n",
       "424    0\n",
       "568    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       132\n",
      "           1       0.75      0.57      0.65        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.76      0.73      0.73       214\n",
      "weighted avg       0.76      0.76      0.75       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare actual y values from validate to predictions based on X_validate\n",
    "print(classification_report(y_validate, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create blank Random Forest classifier\n",
    "rf1 = RandomForestClassifier(max_depth=10, min_samples_leaf=1, random_state=123)\n",
    "rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit/train the model(random tree classifier) to training data/sample\n",
    "# format: model.fit(X, y)\n",
    "\n",
    "rf1 = rf1.fit(X_train, y_train)\n",
    "rf1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform/make predictions using trained model (the training sample)\n",
    "y_pred = rf1.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.52316668e-01, 1.47683332e-01],\n",
       "       [3.02120370e-01, 6.97879630e-01],\n",
       "       [9.70000000e-01, 3.00000000e-02],\n",
       "       [3.79894180e-03, 9.96201058e-01],\n",
       "       [4.16666667e-04, 9.99583333e-01]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the probabilities for each class\n",
    "# aka get prediction probabilites for each class for each observation in train\n",
    "y_pred_proba = rf1.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23476456 0.09026042 0.0515695  0.03433068 0.22753076 0.02154907\n",
      " 0.30308632 0.0110124  0.0258963 ]\n"
     ]
    }
   ],
   "source": [
    "print(rf1.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1st Random Forest classifier on training set with max depth of 10 and 1 min sample leaf: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the rf model 1\n",
    "print('Accuracy of 1st Random Forest classifier on training set with max depth of 10 and 1 min sample leaf: {:.2f}'\n",
    "      .format(rf1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[307,   0],\n",
       "       [ 14, 177]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  307    0\n",
       "1   14  177"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict_death  predict_survive\n",
       "actual_death              307                0\n",
       "actual_survive             14              177"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn confusion matrix into a dataframe for human legibility\n",
    "conf_df = pd.DataFrame(conf, \n",
    "                       columns=['predict_death', 'predict_survive'], \n",
    "                       index=['actual_death', 'actual_survive'])\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], \n",
    "                         columns=['predict_death', 'predict_survive'], \n",
    "                         index=['actual_death', 'actual_survive'])\n",
    "rubric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       307\n",
      "           1       1.00      0.93      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.956386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977707</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926702</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.963351</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.973114</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.956386  1.000000  0.977707  307.000000\n",
       "survived       1.000000  0.926702  0.961957  191.000000\n",
       "accuracy       0.971888  0.971888  0.971888    0.971888\n",
       "macro avg      0.978193  0.963351  0.969832  498.000000\n",
       "weighted avg   0.973114  0.971888  0.971666  498.000000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaner way to read classification report w/ renamed classes\n",
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "\n",
    "pd.DataFrame(class_report).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1:\n",
      "Accuracy: 0.8955823293172691\n",
      "true positive rate: 0.7696335078534031\n",
      "false positive rate: 0.026058631921824105\n",
      "true negative rate: 9.0\n",
      "false negative rate:0.1282798833819242\n",
      "precision: 0.9483870967741935\n",
      "recall: 0.7696335078534031\n",
      "f1-score: 0.8497109826589596\n",
      "support: [307 191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "#accuracy\n",
    "accuracy1 = accuracy_score(y_train, y_pred)\n",
    "\n",
    "#true positive rate\n",
    "tpr1 = tp / (tp + fn)\n",
    "\n",
    "#false positive rate \n",
    "fpr1 = fp / (fp + tn)\n",
    "\n",
    "#true negative rate (specificity)\n",
    "tnr1 = tn / tn + fp\n",
    "\n",
    "#false negative rate (miss rate)\n",
    "fnr1 = fn / (fn + tn)\n",
    "\n",
    "#precision (positive predictive value)\n",
    "precision1 = precision_score(y_train, y_pred)\n",
    "\n",
    "#recall (sensitivity)\n",
    "recall1 = recall_score(y_train, y_pred)\n",
    "\n",
    "#f1-score\n",
    "f11 = f1_score(y_train, y_pred)\n",
    "\n",
    "#support (number of occurrences of each class in y_true)\n",
    "support1 = precision_recall_fscore_support(y_train, y_pred)[-1]\n",
    "\n",
    "\n",
    "print(f'''\n",
    "Model 1:\n",
    "Accuracy: {accuracy1}\n",
    "true positive rate: {tpr1}\n",
    "false positive rate: {fpr1}\n",
    "true negative rate: {tnr1}\n",
    "false negative rate:{fnr1}\n",
    "precision: {precision1}\n",
    "recall: {recall1}\n",
    "f1-score: {f11}\n",
    "support: {support1}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, min_samples_leaf=3, random_state=123)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create 2nd blank Random Forest classifier\n",
    "rf2 = RandomForestClassifier(max_depth=8, min_samples_leaf=3, random_state=123)\n",
    "rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit/train the model(random tree classifier) to training data/sample\n",
    "# format: model.fit(X, y)\n",
    "\n",
    "rf2 = rf2.fit(X_train, y_train)\n",
    "rf2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform/make predictions using trained model (the training sample)\n",
    "y_pred = rf2.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70224372, 0.29775628],\n",
       "       [0.60054726, 0.39945274],\n",
       "       [0.92136111, 0.07863889],\n",
       "       [0.03732751, 0.96267249],\n",
       "       [0.02770117, 0.97229883]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the probabilities for each class\n",
    "# aka get prediction probabilites for each class for each observation in train\n",
    "y_pred_proba = rf2.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15666828 0.11414457 0.04712091 0.0246642  0.18618595 0.02031131\n",
      " 0.41601814 0.01178589 0.02310073]\n"
     ]
    }
   ],
   "source": [
    "print(rf2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 2nd Random Forest classifier on training set with max depth of 8 and 3 min sample leaves: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the rf model 2\n",
    "print('Accuracy of 2nd Random Forest classifier on training set with max depth of 8 and 3 min sample leaves: {:.2f}'\n",
    "      .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299,   8],\n",
       "       [ 44, 147]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  299    8\n",
       "1   44  147"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>44</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict_death  predict_survive\n",
       "actual_death              299                8\n",
       "actual_survive             44              147"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn confusion matrix into a dataframe\n",
    "conf_df = pd.DataFrame(conf, \n",
    "                       columns=['predict_death', 'predict_survive'], \n",
    "                       index=['actual_death', 'actual_survive'])\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>true negative</td>\n",
       "      <td>false positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>false negative</td>\n",
       "      <td>true positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predict_death predict_survive\n",
       "actual_death     true negative  false positive\n",
       "actual_survive  false negative   true positive"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a key for reference\n",
    "rubric_df = pd.DataFrame([['true negative', 'false positive'],['false negative', 'true positive']], \n",
    "                         columns=['predict_death', 'predict_survive'], \n",
    "                         index=['actual_death', 'actual_survive'])\n",
    "rubric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       307\n",
      "           1       0.95      0.77      0.85       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.87      0.88       498\n",
      "weighted avg       0.90      0.90      0.89       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.871720</td>\n",
       "      <td>0.973941</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.849711</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.895582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.910054</td>\n",
       "      <td>0.871787</td>\n",
       "      <td>0.884855</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.901125</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.893042</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.871720  0.973941  0.920000  307.000000\n",
       "survived       0.948387  0.769634  0.849711  191.000000\n",
       "accuracy       0.895582  0.895582  0.895582    0.895582\n",
       "macro avg      0.910054  0.871787  0.884855  498.000000\n",
       "weighted avg   0.901125  0.895582  0.893042  498.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaner way to read classification report w/ renamed classes\n",
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "\n",
    "pd.DataFrame(class_report).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2:\n",
      "Accuracy: 0.8955823293172691\n",
      "true positive rate: 0.7696335078534031\n",
      "false positive rate: 0.026058631921824105\n",
      "true negative rate: 9.0\n",
      "false negative rate:0.1282798833819242\n",
      "precision: 0.9483870967741935\n",
      "recall: 0.7696335078534031\n",
      "f1-score: 0.8497109826589596\n",
      "support: [307 191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "#accuracy\n",
    "accuracy2 = accuracy_score(y_train, y_pred)\n",
    "\n",
    "#true positive rate\n",
    "tpr2 = tp / (tp + fn)\n",
    "\n",
    "#false positive rate \n",
    "fpr2 = fp / (fp + tn)\n",
    "\n",
    "#true negative rate (specificity)\n",
    "tnr2 = tn / tn + fp\n",
    "\n",
    "#false negative rate (miss rate)\n",
    "fnr2 = fn / (fn + tn)\n",
    "\n",
    "#precision (positive predictive value)\n",
    "precision2 = precision_score(y_train, y_pred)\n",
    "\n",
    "#recall (sensitivity)\n",
    "recall2 = recall_score(y_train, y_pred)\n",
    "\n",
    "#f1-score\n",
    "f12 = f1_score(y_train, y_pred)\n",
    "\n",
    "#support (number of occurrences of each class in y_true)\n",
    "support2 = precision_recall_fscore_support(y_train, y_pred)[-1]\n",
    "\n",
    "\n",
    "print(f'''\n",
    "Model 2:\n",
    "Accuracy: {accuracy2}\n",
    "true positive rate: {tpr2}\n",
    "false positive rate: {fpr2}\n",
    "true negative rate: {tnr2}\n",
    "false negative rate:{fnr2}\n",
    "precision: {precision2}\n",
    "recall: {recall2}\n",
    "f1-score: {f12}\n",
    "support: {support2}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=7, random_state=123)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create 2nd blank Random Forest classifier\n",
    "rf3 = RandomForestClassifier(max_depth=5, min_samples_leaf=7, random_state=123)\n",
    "rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit/train the model(random tree classifier) to training data/sample\n",
    "# format: model.fit(X, y)\n",
    "\n",
    "rf3 = rf3.fit(X_train, y_train)\n",
    "rf3.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform/make predictions using trained model (the training sample)\n",
    "y_pred = rf3.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64525716, 0.35474284],\n",
       "       [0.69186847, 0.30813153],\n",
       "       [0.91195197, 0.08804803],\n",
       "       [0.1175142 , 0.8824858 ],\n",
       "       [0.06352455, 0.93647545]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the probabilities for each class\n",
    "# aka get prediction probabilites for each class for each observation in train\n",
    "y_pred_proba = rf3.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09166597 0.1341021  0.03944417 0.01761992 0.14594578 0.02377049\n",
      " 0.52101339 0.0105988  0.01583938]\n"
     ]
    }
   ],
   "source": [
    "print(rf3.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 3rd Random Forest classifier on training set with max depth of 5 and 7 min sample leaves: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the rf model 3\n",
    "print('Accuracy of 3rd Random Forest classifier on training set with max depth of 5 and 7 min sample leaves: {:.2f}'\n",
    "      .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>299</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>44</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predict_death  predict_survive\n",
       "actual_death              299                8\n",
       "actual_survive             44              147"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix into a dataframe\n",
    "conf_df = pd.DataFrame(conf, \n",
    "                       columns=['predict_death', 'predict_survive'], \n",
    "                       index=['actual_death', 'actual_survive'])\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceased</th>\n",
       "      <td>0.819718</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.888112</td>\n",
       "      <td>0.664921</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.839357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853915</td>\n",
       "      <td>0.806402</td>\n",
       "      <td>0.819817</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.845950</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.833638</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "deceased       0.819718  0.947883  0.879154  307.000000\n",
       "survived       0.888112  0.664921  0.760479  191.000000\n",
       "accuracy       0.839357  0.839357  0.839357    0.839357\n",
       "macro avg      0.853915  0.806402  0.819817  498.000000\n",
       "weighted avg   0.845950  0.839357  0.833638  498.000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaner way to read classification report w/ renamed classes\n",
    "class_report = classification_report(y_train, y_pred, output_dict=True)\n",
    "\n",
    "pd.DataFrame(class_report).rename(columns={'0': 'deceased', '1': 'survived'}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 3:\n",
      "Accuracy: 0.8393574297188755\n",
      "true positive rate: 0.6649214659685864\n",
      "false positive rate: 0.05211726384364821\n",
      "true negative rate: 17.0\n",
      "false negative rate:0.18028169014084508\n",
      "precision: 0.8881118881118881\n",
      "recall: 0.6649214659685864\n",
      "f1-score: 0.7604790419161678\n",
      "support: [307 191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
    "\n",
    "#accuracy\n",
    "accuracy3 = accuracy_score(y_train, y_pred)\n",
    "\n",
    "#true positive rate\n",
    "tpr3 = tp / (tp + fn)\n",
    "\n",
    "#false positive rate \n",
    "fpr3 = fp / (fp + tn)\n",
    "\n",
    "#true negative rate (specificity)\n",
    "tnr3 = tn / tn + fp\n",
    "\n",
    "#false negative rate (miss rate)\n",
    "fnr3 = fn / (fn + tn)\n",
    "\n",
    "#precision (positive predictive value)\n",
    "precision3 = precision_score(y_train, y_pred)\n",
    "\n",
    "#recall (sensitivity)\n",
    "recall3 = recall_score(y_train, y_pred)\n",
    "\n",
    "#f1-score\n",
    "f13 = f1_score(y_train, y_pred)\n",
    "\n",
    "#support (number of occurrences of each class in y_true)\n",
    "support3 = precision_recall_fscore_support(y_train, y_pred)[-1]\n",
    "\n",
    "\n",
    "print(f'''\n",
    "Model 3:\n",
    "Accuracy: {accuracy3}\n",
    "true positive rate: {tpr3}\n",
    "false positive rate: {fpr3}\n",
    "true negative rate: {tnr3}\n",
    "false negative rate:{fnr3}\n",
    "precision: {precision3}\n",
    "recall: {recall3}\n",
    "f1-score: {f13}\n",
    "support: {support3}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "- Model 1 performs the best\n",
    "    - highest accuracy\n",
    "    - same precision and recall as model 2\n",
    "    - higher precision and recall than model 3\n",
    "- Model 1 may be overfitted to the data\n",
    "    - performs better in-sample because it is too specific for the data it is training for\n",
    "- Model 1 max depth = 10 means more the splits it has and captures more information about the data\n",
    "    - too much causes overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "-------\n",
      "max_depth=10, min_samples_leaf=1\n",
      " \n",
      "Accuracy on Train: 0.97\n",
      "Precision: 0.95\n",
      "Recall: 0.77\n",
      " \n",
      "\n",
      "Model 2\n",
      "-------\n",
      "max_depth=8, min_samples_leaf=3\n",
      " \n",
      "Accuracy on Train: 0.90\n",
      "Precision: 0.95\n",
      "Recall: 0.77\n",
      " \n",
      "\n",
      "Model 3\n",
      "-------\n",
      "max_depth=5, min_samples_leaf=7\n",
      " \n",
      "Accuracy on Train: 0.84\n",
      "Precision: 0.89\n",
      "Recall:  0.66\n"
     ]
    }
   ],
   "source": [
    "print('Model 1')\n",
    "print('-------')\n",
    "print('max_depth=10, min_samples_leaf=1')\n",
    "print(' ')\n",
    "print('Accuracy on Train: {:.2f}' .format(rf1.score(X_train, y_train)))\n",
    "print(f'Precision: {precision1:.2}')\n",
    "print(f'Recall: {recall1:.2}')\n",
    "print(' ')\n",
    "\n",
    "print('\\nModel 2')\n",
    "print('-------')\n",
    "print('max_depth=8, min_samples_leaf=3')\n",
    "print(' ')\n",
    "print('Accuracy on Train: {:.2f}' .format(rf2.score(X_train, y_train)))\n",
    "print(f'Precision: {precision2:.2}')\n",
    "print(f'Recall: {recall2:.2}')\n",
    "print(' ')\n",
    "\n",
    "print('\\nModel 3')\n",
    "print('-------')\n",
    "print('max_depth=5, min_samples_leaf=7')\n",
    "print(' ')\n",
    "print('Accuracy on Train: {:.2f}'.format(rf3.score(X_train, y_train)))\n",
    "print(f'Precision: {precision3:.2}')\n",
    "print(f'Recall: {recall3: .2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "- Model 1 was overfitted to the train data, did not show consistency from train to validate\n",
    "- Model 3 was most consistent from train to validate\n",
    "- Model 2 shows consistency from train to validate \n",
    "- Both Model 2 and 3 have overall lower scores than Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "-------\n",
      "Accuracy on validate set: 0.77\n",
      " \n",
      " \n",
      "Model 2\n",
      "-------\n",
      "Accuracy on validate set: 0.79\n",
      " \n",
      " \n",
      "Model 3\n",
      "-------\n",
      "Accuracy on validate set: 0.79\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('Model 1')\n",
    "print('-------')\n",
    "print('Accuracy on validate set: {:.2f}'\n",
    "     .format(rf1.score(X_validate, y_validate)))\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print('Model 2')\n",
    "print('-------')\n",
    "print('Accuracy on validate set: {:.2f}'\n",
    "     .format(rf2.score(X_validate, y_validate)))\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print('Model 3')\n",
    "print('-------')\n",
    "print('Accuracy on validate set: {:.2f}'\n",
    "     .format(rf3.score(X_validate, y_validate)))\n",
    "print(' ')\n",
    "print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
